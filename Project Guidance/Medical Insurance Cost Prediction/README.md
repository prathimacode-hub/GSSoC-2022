**MEDICAL INSURANCE COST PREDICTION**

**GOAL**

The main goal of the project is to predict medical insurance cost prediction

**DATASET**

https://www.kaggle.com/subhakarks/medical-insurance-cost-analysis-and-prediction/data

**DESCRIPTION**

It helps in analyzing the cost and predicting the medical insurance based on various paramters from dataset taken into consideration.

**WHAT I HAD DONE**

- Exploratory Data Analysis
- One Hot Encoding
- Feature Engineering
- Assign Feature & Target Variables
- Splitting Data into Training & Testing
- Modelling using 6 different algorithms

**MODELS USED**

- Random Forest Regressor
- Gradient Boosting Regressor
- Bagging Regressor
- Linear Regressor
- Decision Tree Regressor
- XgBoost Regressor

**LIBRARIES NEEDED**

- pandas
- numpy
- seaborn
- scikit_learn
- matplotlib

**ACCURACIES**

### Random Forest Regressor 

Random Forest score on cross validation: 83.64966352368% <br>
Random Forest model score on Training data: 97.54689847160938% <br>
Random Forest model score on Testing data: 87.8044728690866% <br>
R2 Score for Random Forest is 87.8044728690866% <br>

### Gradient Boosting Regressor

Gradient Boosting score on cross validation: 85.88089980680277% <br>
Gradient Boosting model score on Training data: 87.56971335340222% <br>
Gradient Boosting model score on Testing data: 90.31397017745724% <br>
R2 Score for Gradient Boosting is 90.31397017745724% <br>

### Bagging Regressor

Bagging score on cross validation: 83.64029867063427% <br>
Bagging model score on Training data: 97.5188435110028% <br>
Bagging model score on Testing data: 87.8181893771668% <br>
R2 Score for Bagging is 87.8181893771668% <br>

### Linear Regressor

Linear Regression score on cross validation: 74.45419594396432% <br>
Linear Regression model score on Training data: 73.44150173746569% <br>
Linear Regression model score on Testing data: 79.67931786095923% <br>
R2 Score for Linear Regression is 79.67931786095923% <br>

### Decision Tree Regressor

Decision Tree score on cross validation: 66.62918123556328% <br>
Decision Tree model score on Training data: 99.94547916438285% <br>
Decision Tree model score on Testing data: 70.23554900509157% <br>
R2 Score for Decision Tree is 70.23554900509157% <br>

### XgBoost Regressor

XGBoost score on cross validation: 82.14000518115361% <br>
XGBoost model score on Training data: 99.76957955854853% <br>
XGBoost model score on Testing data: 84.97289455714811% <br>
R2 Score for XGBoost is 84.97289455714811% <br>

**YOUR NAME**

Prathima Kadari
