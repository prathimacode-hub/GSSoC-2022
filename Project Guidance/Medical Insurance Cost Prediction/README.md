**MEDICAL INSURANCE COST PREDICTION**

**GOAL**

The main goal of the project is to predict medical insurance cost prediction

**DATASET**

https://www.kaggle.com/subhakarks/medical-insurance-cost-analysis-and-prediction/data

**DESCRIPTION**

It helps in analyzing the cost and predicting the medical insurance based on various paramters from dataset taken into consideration.

**WHAT I HAD DONE**

- Exploratory Data Analysis
- One Hot Encoding
- Feature Engineering
- Assign Feature & Target Variables
- Splitting Data into Training & Testing
- Modelling using 6 different algorithms

**MODELS USED**

- Random Forest Regressor
- Gradient Boosting Regressor
- Bagging Regressor
- Linear Regressor
- Decision Tree Regressor
- XgBoost Regressor

**LIBRARIES NEEDED**

- pandas
- numpy
- seaborn
- scikit_learn
- matplotlib

**ACCURACIES**

### Random Forest Regressor 

Random Forest score on cross validation: 83.64966352368%
Random Forest model score on Training data: 97.54689847160938%
Random Forest model score on Testing data: 87.8044728690866%
R2 Score for Random Forest is 87.8044728690866%

### Gradient Boosting Regressor

Gradient Boosting score on cross validation: 85.88089980680277%
Gradient Boosting model score on Training data: 87.56971335340222%
Gradient Boosting model score on Testing data: 90.31397017745724%
R2 Score for Gradient Boosting is 90.31397017745724%

### Bagging Regressor

Bagging score on cross validation: 83.64029867063427%
Bagging model score on Training data: 97.5188435110028%
Bagging model score on Testing data: 87.8181893771668%
R2 Score for Bagging is 87.8181893771668%

### Linear Regressor

Linear Regression score on cross validation: 74.45419594396432%
Linear Regression model score on Training data: 73.44150173746569%
Linear Regression model score on Testing data: 79.67931786095923%
R2 Score for Linear Regression is 79.67931786095923%

### Decision Tree Regressor

Decision Tree score on cross validation: 66.62918123556328%
Decision Tree model score on Training data: 99.94547916438285%
Decision Tree model score on Testing data: 70.23554900509157%
R2 Score for Decision Tree is 70.23554900509157%

### XgBoost Regressor

XGBoost score on cross validation: 82.14000518115361%
XGBoost model score on Training data: 99.76957955854853%
XGBoost model score on Testing data: 84.97289455714811%
R2 Score for XGBoost is 84.97289455714811%

**YOUR NAME**

Prathima Kadari
